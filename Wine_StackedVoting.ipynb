{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique 'qualities': 7\n",
      "Qualities: [3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "Class counts: [   0    0    0   20  163 1457 2198  880  175    5]\n",
      "\n",
      "Number of instances: 4898 \n",
      "\n",
      "Class fractions: [ 0.    0.    0.    0.41  3.33 29.75 44.88 17.97  3.57  0.1 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = Path(\"./winequality-white.csv\")\n",
    "data_columns = [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \n",
    "\"pH\", \"sulphates\", \"alcohol\", \"quality\"]\n",
    "wine_df = pd.read_csv(data_path, header=0, names=data_columns, sep=\";\")\n",
    "\n",
    "test_size=0.2\n",
    "train_df, test_df = train_test_split(wine_df, test_size=test_size)\n",
    "\n",
    "# data overview:\n",
    "#print(wine_df.describe())\n",
    "\n",
    "# which quality classes do we have? :\n",
    "qualities = wine_df[\"quality\"].unique()\n",
    "print(f\"Number of unique 'qualities': {len(qualities)}\")\n",
    "print(f\"Qualities: {sorted(qualities)}\")\n",
    "binc = np.bincount([q for q in wine_df[\"quality\"]])\n",
    "no_inst = len(wine_df)\n",
    "print(f\"\\nClass counts: {binc}\")\n",
    "print(f\"\\nNumber of instances: {no_inst} \")\n",
    "print(f\"\\nClass fractions: {np.round(binc/no_inst,4) * 100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_dataframe(data_df, exempt_last_column=True,column_names_to_scale=None):\n",
    "    \"\"\"\n",
    "        Scales columns of a given data frame with a StandardScaler from Sklearn. \n",
    "        Input:\n",
    "            data_df : dataframe with numerical values to normalize\n",
    "            exempt_last_column : if true, column_names_to_scale will be ignored and all but the last column will be scaled.\n",
    "            column_names_to_scale : list of the names of the columns to be scaled\n",
    "\n",
    "        Output:\n",
    "            dataframe with columns scaled\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    if(exempt_last_column):\n",
    "        data = data_df.to_numpy()\n",
    "        data_to_scale = data[:,:-1]\n",
    "        last_column = np.expand_dims(data[:,-1].astype(np.int_), axis=1)\n",
    "        data_scaled = np.append(scaler.fit_transform(data_to_scale), last_column, axis=1)\n",
    "        return pd.DataFrame(data_scaled)\n",
    "    elif(column_names_to_normalize):\n",
    "        data_to_scale = data_df[column_names_to_scale].to_numpy()\n",
    "        data_scaled = scaler.fit_transform(data_to_scale)\n",
    "        df_temp = pd.DataFrame(data_scaled, columns=column_names_to_scale, index=data_df.index)\n",
    "        data_df[column_names_to_scale]= df_temp\n",
    "    else:\n",
    "        data_to_scale = data_df.to_numpy()\n",
    "        data_scaled = scaler.fit_transform(data_to_scale)\n",
    "        data_df = pd.DataFrame(data_scaled)\n",
    "    \n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition from the WineDataset note book -- I don't know how to import from another Jupyter notebook...\n",
    "class WineNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WineNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(11, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    losses, nof_correct = 0, 0\n",
    "    for xx, y_true in dataloader:\n",
    "        y_pred = model(xx)\n",
    "        loss= loss_fn(y_pred, y_true)\n",
    "        losses += loss.item()\n",
    "        nof_correct += (y_pred.argmax(1) == y_true).sum().item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses, nof_correct\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    losses, no_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for (X,y_true) in dataloader:\n",
    "            pred = model(X)\n",
    "            losses += loss_fn(pred, y_true).item()\n",
    "            no_correct += (pred.argmax(1)== y_true).sum().item()\n",
    "     \n",
    "    return losses, no_correct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training data with the decision-tree:\n",
    "\n",
    "import pickle\n",
    "\n",
    "Wine_tree_filename = 'AdaBoost_071_model.dct'\n",
    "\n",
    "def Wine_tree_map(data_df, tree_name):\n",
    "    \"\"\"\n",
    "    Maps a data-frame by using a pre-trained decision-tree.\n",
    "    Input:\n",
    "        data_df : Pandas data-frame to be mapped\n",
    "        tree_name : path / name of the pretrained tree\n",
    "    Returns:\n",
    "        Pandas data-frame\n",
    "    \"\"\"\n",
    "    tree_model = pickle.load(open(tree_name, 'rb'))\n",
    "    X = data_df.to_numpy()\n",
    "    # \"np.int_\" is \"long\" in numpy:\n",
    "    # predict_proba:\n",
    "    #Z = np.append(tree_model.predict_proba(X[:,:-1]), np.expand_dims(X[:,-1].astype(np.int_), axis=1), axis=1)\n",
    "    \n",
    "    # predict:\n",
    "    Z = np.append(np.expand_dims(tree_model.predict(X[:,:-1]).astype(np.int_), axis=1), np.expand_dims(X[:,-1].astype(np.int_), axis=1), axis=1)\n",
    "    \n",
    "    return pd.DataFrame(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps the training data with the neural-net:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "WineNetwork_filename = \"model_640_0.001_369_64_SGD.pt\"\n",
    "\n",
    "def WineNetwork_map(data_df, net_name):\n",
    "    \"\"\"\n",
    "    Maps a dataframe by applying a pre-trained neural net of type \"class WineNetwork\"\n",
    "    Input:\n",
    "        data_df : the pandas data-frame to be transformed\n",
    "        net_name : the path / name of the neural net of type WineNetwork to be loaded\n",
    "    Returns:\n",
    "        a pandas data-frame        \n",
    "    \"\"\"\n",
    "    class WineNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(WineNetwork, self).__init__()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(11, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(64),\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.Linear(64, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.Linear(128, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.Linear(256, 10),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits\n",
    "\n",
    "    net_model = WineNetwork()\n",
    "    net_model.load_state_dict(torch.load(net_name))\n",
    "    net_model.eval()\n",
    "    # softm = lambda x : np.exp(x)/np.sum(np.exp(x))\n",
    "    softm = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    X = torch.tensor(data_df.iloc[:,:-1].to_numpy(), dtype=torch.float32).detach()\n",
    "    Y = torch.tensor(data_df.iloc[:, -1].to_numpy(), dtype=torch.long).detach()\n",
    "\n",
    "    Z = torch.cat((softm(net_model(X)), Y.unsqueeze(dim=1)), dim=1).detach().numpy()\n",
    "    \n",
    "    return pd.DataFrame(Z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define torch.dataset: __init__(), __len__(), __getitem__()\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WineDataSet(Dataset):\n",
    "    def __init__(self, data_df, transform=None, target_transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.X = torch.tensor(self.data_df.iloc[:,:-1].to_numpy(), dtype=torch.float32)\n",
    "        self.Y = torch.tensor(self.data_df.iloc[:, -1].to_numpy(), dtype= torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        self.x = self.X[idx,:]\n",
    "        self.y = self.Y[idx]\n",
    "        if self.transform != None:\n",
    "            self.x = self.transform(self.x)\n",
    "        if self.target_transform != None:\n",
    "            self.y = self.target_transform(self.y)\n",
    "        return self.x, self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data:\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_path = Path(\"./winequality-white.csv\")\n",
    "column_names = [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \n",
    "\"pH\", \"sulphates\", \"alcohol\", \"quality\"]\n",
    "#column_names_to_normalize = column_names[:-1]\n",
    "wine_df = pd.read_csv(data_path, header=0, names=column_names, sep=\";\")\n",
    "\n",
    "# prepare data:\n",
    "shuffle(wine_df, random_state=0)\n",
    "scaled_wine_df = normalize_dataframe(wine_df, exempt_last_column=True)\n",
    "\n",
    "WineNetwork_filename = \"model_640_0.001_369_64_SGD.pt\"\n",
    "Wine_tree_filename = 'AdaBoost_071_model.dct'\n",
    "\n",
    "net_df = WineNetwork_map(scaled_wine_df, net_name=WineNetwork_filename)\n",
    "net_df = normalize_dataframe(net_df)\n",
    "tree_df = Wine_tree_map(wine_df, tree_name=Wine_tree_filename)\n",
    "tree_df = normalize_dataframe(tree_df)\n",
    "\n",
    "# combine net_df and tree_df to combined_data_df:\n",
    "combined_data_df = pd.DataFrame(np.append(net_df.iloc[:,:-1].to_numpy(), tree_df.to_numpy(), axis=1))\n",
    "\n",
    "# split into train_df, test_df:\n",
    "test_size = 0.2\n",
    "combined_train_df, combined_test_df = train_test_split(combined_data_df, test_size=test_size)\n",
    "blender_input_dim = combined_data_df.shape[1]-1\n",
    "\n",
    "# create dataloader from train_df and test_df:\n",
    "batch_size=64\n",
    "train_ds = WineDataSet(combined_train_df)\n",
    "test_ds = WineDataSet(combined_test_df)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender_input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class BlenderModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(input_dim, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(128, 10),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "----- Epoch: 50 -----\n",
      "Epoch loss: 0.03956298901110279\n",
      "Epoch accuracy: 0.0163265306122449\n",
      "\n",
      "----- Epoch: 100 -----\n",
      "Epoch loss: 0.03973532501532107\n",
      "Epoch accuracy: 0.015306122448979591\n",
      "\n",
      "----- Epoch: 150 -----\n",
      "Epoch loss: 0.03985172242534404\n",
      "Epoch accuracy: 0.015306122448979591\n",
      "\n",
      "----- Epoch: 200 -----\n",
      "Epoch loss: 0.03962579138424932\n",
      "Epoch accuracy: 0.0163265306122449\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# writer for tensorboard:\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# parameters:\n",
    "\n",
    "# loss function:\n",
    "# cross-entropy:\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer:\n",
    "\n",
    "# adam:\n",
    "optimizer_name = \"ADAM\"\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# sgd:\n",
    "#optimizer_name = \"SGD\"\n",
    "#learning_rate = 1e-3\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9)\n",
    "\n",
    "epochs = 100\n",
    "write_log_after_epochs = 20\n",
    "best_model_name = \"\"\n",
    "max_correct = -torch.inf\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = BlenderModel(blender_input_dim)\n",
    "\n",
    "for ep in range(1, epochs+1):        \n",
    "       \n",
    "        # put model in train mode:\n",
    "        model.train()\n",
    "        (train_loss, train_no_correct) = train_loop(train_dl, model, loss_fn, optimizer)\n",
    "              \n",
    "        # switch model to to evaluation mode:\n",
    "        model.eval()\n",
    "        (test_loss, test_no_correct) = test_loop(test_dl, model, loss_fn)\n",
    "\n",
    "        if(test_no_correct > max_correct):\n",
    "            max_correct = test_no_correct\n",
    "            if(best_model_name):\n",
    "                os.remove(best_model_name)\n",
    "            best_model_name = \"./blender_model_\" + str(test_no_correct) + \"_\" + str(learning_rate) + \"_\" + str(ep) + \"_\" + str(batch_size) + \"_\" + optimizer_name + \"_sv.pt\"\n",
    "            torch.save(model.state_dict(), best_model_name)\n",
    "\n",
    "        writer.add_scalar(\"Loss/test\", test_loss/ len(test_ds), ep)\n",
    "        writer.add_scalar(\"Accuracy/test\", test_no_correct/ len(test_ds), ep)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss/ len(train_ds), global_step=ep)\n",
    "        writer.add_scalar(\"Accuracy/train\", train_no_correct/ len(train_ds), global_step=ep)\n",
    "       \n",
    "        if ep % write_log_after_epochs == 0:\n",
    "            print(f\"\\n----- Epoch: {ep} -----\")\n",
    "            print(f\"Epoch loss: {test_loss/ len(test_ds)}\")\n",
    "            print(f\"Epoch accuracy: {test_no_correct/ len(test_ds)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlenderModel(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=17, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=10, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63c4844b7ff1ba2a0ea33a2a697d60509a196ce3d2a18c44c2b4fb054ba492a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('conenv_fileassociation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
