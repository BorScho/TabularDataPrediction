{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fully connected neural net to qualify wine according to chemical analysis. #\r\n",
    "\r\n",
    "Wine data-set downloaded from [csv-file](http://mng.bz/90Ol)\r\n",
    "\r\n",
    "* Two hidden layers\r\n",
    "* ADAM optimizer: learning rate: 1e-4\r\n",
    "* epochs = 600\r\n",
    "* accuracy: 85.20%\r\n",
    "\r\n",
    "Training:\r\n",
    "\r\n",
    "----- Epoch: 100 -----\r\n",
    "Epoch loss: 0.0298558915147976\r\n",
    "Epoch accuracy: 0.6173469387755102\r\n",
    "\r\n",
    "----- Epoch: 200 -----\r\n",
    "Epoch loss: 0.02590804458880911\r\n",
    "Epoch accuracy: 0.6816326530612244\r\n",
    "\r\n",
    "----- Epoch: 300 -----\r\n",
    "Epoch loss: 0.021330454793511606\r\n",
    "Epoch accuracy: 0.7357142857142858\r\n",
    "\r\n",
    "----- Epoch: 400 -----\r\n",
    "Epoch loss: 0.018781860081516968\r\n",
    "Epoch accuracy: 0.7857142857142857\r\n",
    "\r\n",
    "----- Epoch: 500 -----\r\n",
    "Epoch loss: 0.015203852860295042\r\n",
    "Epoch accuracy: 0.8397959183673469\r\n",
    "\r\n",
    "----- Epoch: 600 -----\r\n",
    "Epoch loss: 0.013255607230322701\r\n",
    "Epoch accuracy: 0.8520408163265306\r\n",
    "----- Finished Training -----\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training with kFold cross-validation: ###\r\n",
    "\r\n",
    "* Two hidden layers\r\n",
    "* ADAM optimizer: learning rate: 1e-4\r\n",
    "* number of folds: 5\r\n",
    "* epochs = 600\r\n",
    "* accuracy: 87.08%\r\n",
    "* runtime: 1969.8s\r\n",
    "\r\n",
    "----- Epoch: 100 -----\r\n",
    "Epoch loss (avg. all folds): 0.025227703386630017\r\n",
    "Epoch accuracy (avg. all folds): 0.7076557482645764\r\n",
    "\r\n",
    "----- Epoch: 200 -----\r\n",
    "Epoch loss (avg. all folds): 0.018748069187298207\r\n",
    "Epoch accuracy (avg. all folds): 0.7878191282233015\r\n",
    "\r\n",
    "----- Epoch: 300 -----\r\n",
    "Epoch loss (avg. all folds): 0.015001535402682996\r\n",
    "Epoch accuracy (avg. all folds): 0.8273287242987082\r\n",
    "\r\n",
    "----- Epoch: 400 -----\r\n",
    "Epoch loss (avg. all folds): 0.012860514906850948\r\n",
    "Epoch accuracy (avg. all folds): 0.8486841930541368\r\n",
    "\r\n",
    "----- Epoch: 500 -----\r\n",
    "Epoch loss (avg. all folds): 0.01152177774778462\r\n",
    "Epoch accuracy (avg. all folds): 0.8618339396718852\r\n",
    "\r\n",
    "----- Epoch: 600 -----\r\n",
    "Epoch loss (avg. all folds): 0.010597546124541527\r\n",
    "Epoch accuracy (avg. all folds): 0.8708151622855476\r\n",
    "----- Finished Training -----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "data_path = Path(\"./winequality-white.csv\")\r\n",
    "wine_df = pd.read_csv(data_path, header=0, names=[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \r\n",
    "\"pH\", \"sulphates\", \"alcohol\", \"quality\"], sep=\";\")\r\n",
    "\r\n",
    "# data overview:\r\n",
    "print(wine_df.describe())\r\n",
    "\r\n",
    "# which quality classes do we have? :\r\n",
    "qualities = wine_df[\"quality\"].unique()\r\n",
    "print(f\"Number of unique 'qualities': {len(qualities)}\")\r\n",
    "print(f\"Qualities: {sorted(qualities)}\")\r\n",
    "binc = np.bincount([q for q in wine_df[\"quality\"]])\r\n",
    "no_inst = len(wine_df)\r\n",
    "print(f\"\\nClass counts: {binc}\")\r\n",
    "print(f\"\\nNumber of instances: {no_inst} \")\r\n",
    "print(f\"\\nClass fractions: {np.round(binc/no_inst,4) * 100}\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "\r\n",
    "# Get cpu or gpu device for training.\r\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "print(\"Using {} device\".format(device))\r\n",
    "\r\n",
    "# Define model\r\n",
    "class WineNetwork(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(WineNetwork, self).__init__()\r\n",
    "        self.linear_relu_stack = nn.Sequential(\r\n",
    "            nn.Linear(11, 64),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(64, 128),\r\n",
    "            #nn.Dropout(p=0.2),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(128, 256),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(256, 7),\r\n",
    "            nn.ReLU()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        logits = self.linear_relu_stack(x)\r\n",
    "        return logits\r\n",
    "\r\n",
    "model = WineNetwork().to(device)\r\n",
    "print(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# define torch.dataset: __init__(), __len__(), __getitem__()\r\n",
    "from torch.utils.data import Dataset\r\n",
    "\r\n",
    "class WineDataSet(Dataset):\r\n",
    "    def __init__(self, data_df, transform=None, target_transform=None):\r\n",
    "        self.wine_df = data_df\r\n",
    "        self.transform = transform\r\n",
    "        self.target_transform = target_transform\r\n",
    "        self.X = np.asarray(self.wine_df.iloc[:,:-1].values, dtype=np.float32)\r\n",
    "        self.Y = np.asarray(self.wine_df[\"quality\"].values, dtype= np.int32)\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.Y)\r\n",
    "    def __getitem__(self,idx):\r\n",
    "        self.x = self.X[idx,:]\r\n",
    "        self.y = self.Y[idx]\r\n",
    "        if self.transform != None:\r\n",
    "            self.x = self.transform(self.x)\r\n",
    "        if self.target_transform != None:\r\n",
    "            self.y = self.target_transform(self.y)\r\n",
    "        return self.x, self.y\r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "def normalize_dataframe(data_df, column_names_to_normalize):\r\n",
    "    \"\"\"\r\n",
    "        Normalizes all given columns of a given data frame with a StandardScaler from Sklearn. \r\n",
    "        Input:\r\n",
    "            data_df: dataframe with numerical values to normalize\r\n",
    "            column_names_to_normalize: list of the names of the columns to be normalized\r\n",
    "        Output:\r\n",
    "            dataframe with columns normalized\r\n",
    "    \"\"\"\r\n",
    "    scaler = StandardScaler()\r\n",
    "    data_to_norm = data_df[column_names_to_normalize].values\r\n",
    "    data_normed = scaler.fit_transform(data_to_norm)\r\n",
    "    df_temp = pd.DataFrame(data_normed, columns=column_names_to_normalize, index=data_df.index)\r\n",
    "    data_df[column_names_to_normalize]= df_temp\r\n",
    "    return data_df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Target transformation of the labels:\r\n",
    "from torchvision.transforms import Lambda # might be overkill to call these just for OHE...\r\n",
    "\r\n",
    "# OHE encoding supposing, that the labels y are integer-encoded:\r\n",
    "transform_ohe = Lambda(lambda y: torch.zeros(7, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y - 3), value=1))\r\n",
    "\r\n",
    "# \"quality\" - encoding starting with 0 instead of 3:\r\n",
    "classes_zero_based = { c : c-3 for c in wine_df[\"quality\"].unique()}\r\n",
    "\r\n",
    "target_transform = classes_zero_based.get"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# test and train loops:\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "writer = SummaryWriter()\r\n",
    "\r\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\r\n",
    "    losses, no_correct = 0,0\r\n",
    "    for n_batch, (X, y) in enumerate(dataloader):\r\n",
    "        pred = model(X)\r\n",
    "        loss = loss_fn(pred, y)\r\n",
    "        losses += loss.item()\r\n",
    "        no_correct +=(pred.argmax(1)==y).sum().item()\r\n",
    "\r\n",
    "        optimizer.zero_grad()        \r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "    \r\n",
    "    return losses, no_correct\r\n",
    "        \r\n",
    "\r\n",
    "def test_loop(dataloader, model, loss_fn):\r\n",
    "    losses, no_correct = 0, 0\r\n",
    "    with torch.no_grad():\r\n",
    "        for (X,y) in dataloader:\r\n",
    "            pred = model(X)\r\n",
    "            losses += loss_fn(pred, y).item()\r\n",
    "            no_correct += (pred.argmax(1)== y).sum().item()\r\n",
    "     \r\n",
    "    return losses, no_correct\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train the model:\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\r\n",
    "\r\n",
    "# writer for tensorboard:\r\n",
    "writer = SummaryWriter()\r\n",
    "\r\n",
    "# create new model instance:\r\n",
    "model = WineNetwork().to(device) \r\n",
    "\r\n",
    "# loss function:\r\n",
    "# cross-entropy:\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "# optimizer:\r\n",
    "# adam:\r\n",
    "learning_rate = 1e-4\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "# sgd:\r\n",
    "#learning_rate = 1e-5\r\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9)\r\n",
    "\r\n",
    "# training parameters:\r\n",
    "from pathlib import Path\r\n",
    "data_path = Path(\"./winequality-white.csv\")\r\n",
    "column_names = [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \r\n",
    "\"pH\", \"sulphates\", \"alcohol\", \"quality\"]\r\n",
    "column_names_to_normalize = column_names[:-1]\r\n",
    "wine_df = pd.read_csv(data_path, header=0, names=column_names, sep=\";\")\r\n",
    "\r\n",
    "apply_stratified_kfold = False\r\n",
    "no_folds = 5\r\n",
    "\r\n",
    "epochs = 300\r\n",
    "\r\n",
    "epoch_losses = []\r\n",
    "epoch_no_corrects = []\r\n",
    "train_losses = []\r\n",
    "train_acc = []\r\n",
    "test_losses = []\r\n",
    "test_acc = []\r\n",
    "for ep in range(1, epochs+1):\r\n",
    "\r\n",
    "    if apply_stratified_kfold:\r\n",
    "        X = wine_df[column_names_to_normalize]\r\n",
    "        y = wine_df[\"quality\"].values\r\n",
    "        skf = StratifiedKFold(n_splits=no_folds, shuffle=True, random_state=42)\r\n",
    "        losses, acc = 0, 0\r\n",
    "\r\n",
    "        for fold, (train_ids, test_ids) in enumerate(skf.split(X, y)):\r\n",
    "            train_df = wine_df.iloc[train_ids].copy()\r\n",
    "            train_df = normalize_dataframe(train_df, column_names_to_normalize)\r\n",
    "            test_df = wine_df.iloc[test_ids].copy()\r\n",
    "            test_df = normalize_dataframe(test_df, column_names_to_normalize)\r\n",
    "            train_ds = WineDataSet(data_df=train_df, target_transform=target_transform)\r\n",
    "            test_ds = WineDataSet(data_df=test_df, target_transform=target_transform)\r\n",
    "            train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\r\n",
    "            test_dl = DataLoader(test_ds, batch_size=32, shuffle=True)\r\n",
    "\r\n",
    "            # put model in train mode:\r\n",
    "            model.train()\r\n",
    "            (train_loss, train_no_correct) = train_loop(train_dl, model, loss_fn, optimizer)\r\n",
    "            train_losses.append(train_loss/ len(train_ds))\r\n",
    "            train_acc.append(train_no_correct/ len(train_ds))\r\n",
    "\r\n",
    "            # switch model to to evaluation mode:\r\n",
    "            model.eval()\r\n",
    "            (test_loss, test_no_correct) = test_loop(test_dl, model, loss_fn)\r\n",
    "            test_losses.append(test_loss/len(test_ds))\r\n",
    "            test_acc.append(test_no_correct/ len(test_ds))\r\n",
    "                    \r\n",
    "        if ep % 100 == 0:\r\n",
    "            print(f\"\\n----- Epoch: {ep} -----\")\r\n",
    "            print(f\"Epoch loss (avg. all folds): {np.average(test_losses)}\")\r\n",
    "            print(f\"Epoch accuracy (avg. all folds): {np.average(test_acc)}\")\r\n",
    "            writer.add_scalar(\"Loss/train\", np.average(train_losses), ep)\r\n",
    "            writer.add_scalar(\"Accuracy/train\", np.average(train_acc), ep)\r\n",
    "            writer.add_scalar(\"Loss/test\", np.average(test_losses), ep)\r\n",
    "            writer.add_scalar(\"Accuracy/test\", np.average(test_acc), ep)\r\n",
    "    \r\n",
    "    else:\r\n",
    "        train_df, test_df = train_test_split(wine_df, test_size=0.2)\r\n",
    "        train_df = train_df.copy()\r\n",
    "        test_df = test_df.copy()\r\n",
    "        train_df = normalize_dataframe(train_df, column_names_to_normalize)\r\n",
    "        test_df = normalize_dataframe(test_df, column_names_to_normalize)\r\n",
    "        train_ds = WineDataSet(data_df=train_df, target_transform=target_transform)\r\n",
    "        test_ds = WineDataSet(data_df=test_df, target_transform=target_transform)\r\n",
    "        train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\r\n",
    "        test_dl = DataLoader(test_ds, batch_size=32, shuffle=True)\r\n",
    "        # put model in train mode:\r\n",
    "        model.train()\r\n",
    "        (epoch_loss, epoch_no_correct) = train_loop(train_dl, model, loss_fn, optimizer)\r\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss/len(train_ds), global_step=ep)\r\n",
    "        writer.add_scalar(\"Accuracy/train\", epoch_no_correct/ len(train_ds), global_step=ep)\r\n",
    "        # switch model to to evaluation mode:\r\n",
    "        model.eval()\r\n",
    "        (epoch_loss, epoch_no_correct) = test_loop(test_dl, model, loss_fn)\r\n",
    "        epoch_losses.append(epoch_loss)\r\n",
    "        epoch_no_corrects.append(epoch_no_correct)\r\n",
    "\r\n",
    "        if ep % 100 == 0:\r\n",
    "            print(f\"\\n----- Epoch: {ep} -----\")\r\n",
    "            avg_loss = epoch_loss/ len(test_ds)\r\n",
    "            print(f\"Epoch loss: {avg_loss}\")\r\n",
    "            writer.add_scalar(\"Loss/test\", avg_loss, ep)\r\n",
    "            avg_acc = epoch_no_correct/ len(test_ds)\r\n",
    "            print(f\"Epoch accuracy: {avg_acc}\")\r\n",
    "            writer.add_scalar(\"Accuracy/test\", avg_acc, ep)\r\n",
    "        \r\n",
    "writer.flush()\r\n",
    "writer.close()\r\n",
    "print(\"----- Finished Training -----\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2da2a01206928b59d169f1baf1b7bbbb4ecd1378e37d125bf69781943a3c02b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}