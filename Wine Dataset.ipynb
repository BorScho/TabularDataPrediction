{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13281e8",
   "metadata": {},
   "source": [
    "## Fully Connected Neural Net to Qualify Wine According to Chemical Analysis. ##\n",
    "\n",
    "Wine data-set downloaded from [csv-file](http://mng.bz/90Ol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93754ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique 'qualities': 7\n",
      "Qualities: [3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "Class counts: [   0    0    0   20  163 1457 2198  880  175    5]\n",
      "\n",
      "Number of instances: 4898 \n",
      "\n",
      "Class fractions: [ 0.    0.    0.    0.41  3.33 29.75 44.88 17.97  3.57  0.1 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"./winequality-white.csv\")\n",
    "wine_df = pd.read_csv(data_path, header=0, names=[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \n",
    "\"pH\", \"sulphates\", \"alcohol\", \"quality\"], sep=\";\")\n",
    "\n",
    "# data overview:\n",
    "#print(wine_df.describe())\n",
    "\n",
    "# which quality classes do we have? :\n",
    "qualities = wine_df[\"quality\"].unique()\n",
    "print(f\"Number of unique 'qualities': {len(qualities)}\")\n",
    "print(f\"Qualities: {sorted(qualities)}\")\n",
    "binc = np.bincount([q for q in wine_df[\"quality\"]])\n",
    "no_inst = len(wine_df)\n",
    "print(f\"\\nClass counts: {binc}\")\n",
    "print(f\"\\nNumber of instances: {no_inst} \")\n",
    "print(f\"\\nClass fractions: {np.round(binc/no_inst,4) * 100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6d7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "WineNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=11, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Linear(in_features=256, out_features=10, bias=True)\n",
      "    (11): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class WineNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        #super(WineNetwork, self).__init__()\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(11, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = WineNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3ee77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define torch.dataset: __init__(), __len__(), __getitem__()\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WineDataSet(Dataset):\n",
    "    def __init__(self, data_df, transform=None, target_transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.X = torch.tensor(self.data_df.iloc[:,:-1].values, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(self.data_df.iloc[:,-1].values, dtype= torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        self.x = self.X[idx,:]\n",
    "        self.y = self.Y[idx]\n",
    "        if self.transform != None:\n",
    "            self.x = self.transform(self.x)\n",
    "        if self.target_transform != None:\n",
    "            self.y = self.target_transform(self.y)\n",
    "        return self.x, self.y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7b19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_dataframe(data_df, exempt_last_column=False, column_names_to_scale=None):\n",
    "    \"\"\"\n",
    "        Scales columns of a given data frame with a StandardScaler from Sklearn. \n",
    "        Input:\n",
    "            data_df : dataframe with numerical values to normalize\n",
    "            exempt_last_column : if true, the parameter column_names_to_scale will be ignored and all but the last column will be scaled.\n",
    "            column_names_to_scale : list of the names of the columns to be scaled\n",
    "\n",
    "        Output:\n",
    "            dataframe with columns scaled\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    if(exempt_last_column & (column_names_to_scale != None)):\n",
    "        raise UserWarning(\"exempt_last_column=True : your column_names_to_scale will be ignored!\")\n",
    "    if(exempt_last_column):\n",
    "        print(\"scaler exempting last column\")\n",
    "        data = data_df.to_numpy()\n",
    "        data_to_scale = data[:,:-1]\n",
    "        last_column = np.expand_dims(data[:,-1].astype(np.int_), axis=1)\n",
    "        data_scaled = scaler.fit_transform(data_to_scale)\n",
    "        data_scaled = np.append(data_scaled, last_column, axis=1)\n",
    "        data_df = pd.DataFrame(data_scaled)\n",
    "    elif(column_names_to_scale):\n",
    "        print(\"scaler scaling designated columns\")\n",
    "        data_to_scale = data_df[column_names_to_scale].to_numpy()\n",
    "        data_scaled = scaler.fit_transform(data_to_scale)\n",
    "        df_temp = pd.DataFrame(data_scaled, columns=column_names_to_scale, index=data_df.index)\n",
    "        data_df[column_names_to_scale]= df_temp\n",
    "    else:\n",
    "        print(\"scaler scaling all columns\")\n",
    "        data_to_scale = data_df.to_numpy()\n",
    "        data_scaled = scaler.fit_transform(data_to_scale)\n",
    "        data_df = pd.DataFrame(data_scaled)\n",
    "    \n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# old scaler: \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_dataframe(data_df, exempt_last_column=False, column_names_to_scale=None):\n",
    "    \"\"\"\n",
    "        Scales columns of a given data frame with a StandardScaler from Sklearn. \n",
    "        Input:\n",
    "            data_df : dataframe with numerical values to normalize\n",
    "            exempt_last_column : if true, column_names_to_scale will be ignored and all but the last column will be scaled.\n",
    "            column_names_to_scale : list of the names of the columns to be scaled\n",
    "\n",
    "        Output:\n",
    "            dataframe with columns scaled\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    if(exempt_last_column & (column_names_to_scale != None)):\n",
    "        raise UserWarning(\"exempt_last_column=True : your column_names_to_scale will be ignored!\")\n",
    "    if(exempt_last_column):\n",
    "        data = data_df.to_numpy()\n",
    "        data_to_scale = data[:,:-1]\n",
    "        last_column = np.expand_dims(data[:,-1].astype(np.int_), axis=1)\n",
    "        data_scaled = np.append(scaler.fit_transform(data_to_scale), last_column, axis=1)\n",
    "        return pd.DataFrame(data_scaled)\n",
    "    elif(column_names_to_scale):\n",
    "        data_to_scale = data_df[column_names_to_scale].to_numpy()\n",
    "        data_scaled = scaler.fit_transform(data_to_scale)\n",
    "        df_temp = pd.DataFrame(data_scaled, columns=column_names_to_scale, index=data_df.index)\n",
    "        data_df[column_names_to_scale]= df_temp\n",
    "    else:\n",
    "        data_to_scale = data_df.to_numpy()\n",
    "        data_scaled = scaler.fit_transform(data_to_scale)\n",
    "        data_df = pd.DataFrame(data_scaled)\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IS PROBABLY NOT NEEDED - SEE PYTORCH'S DEFINITION OF CROSSENTROPYLOSS:\n",
    "\n",
    "# OHE encoding of the labels: \n",
    "labels = np.sort(wine_df[\"quality\"].unique())\n",
    "ohe=torch.nn.functional.one_hot(torch.tensor(labels))\n",
    "\n",
    "# make a target_transform for the dataloaders:\n",
    "target_transform = {l:oh for l,oh in zip(labels,ohe)}.get\n",
    "\n",
    "# test the target_transform:\n",
    "target_transform(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15cc7a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and train loops:\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    losses, no_correct = 0, 0\n",
    "    for n_batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        losses += loss.item()\n",
    "        no_correct +=(pred.argmax(1)==y).sum().item()\n",
    "\n",
    "        optimizer.zero_grad()        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses, no_correct\n",
    "        \n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    losses, no_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for (X,y) in dataloader:\n",
    "            pred = model(X)\n",
    "            losses += loss_fn(pred, y).item()\n",
    "            no_correct += (pred.argmax(1)== y).sum().item()\n",
    "     \n",
    "    return losses, no_correct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3922fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape : (3917, 12)\n",
      "test_df.shape : (979, 12)\n",
      "scaler exempting last column\n",
      "scaler exempting last column\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND PREPARE DATA:\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "# load data from winequality-white.csv:\n",
    "\n",
    "from pathlib import Path\n",
    "data_path = Path(\"./winequality-white.csv\")\n",
    "column_names = [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \n",
    "\"pH\", \"sulphates\", \"alcohol\", \"quality\"]\n",
    "column_names_to_normalize = column_names[:-1]\n",
    "wine_df = pd.read_csv(data_path, header=0, names=column_names, sep=\";\")\n",
    "\n",
    "test_size=0.2\n",
    "train_df, test_df = train_test_split(wine_df, test_size=test_size)\n",
    "train_df = scale_dataframe(train_df, column_names_to_scale=column_names_to_normalize, exempt_last_column=False)\n",
    "test_df = scale_dataframe(test_df, column_names_to_scale=column_names_to_normalize, exempt_last_column=False)\n",
    "train_ds = WineDataSet(data_df=train_df)\n",
    "test_ds = WineDataSet(data_df=test_df)\n",
    "\n",
    "batch_size=64\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "\"\"\"\n",
    "\n",
    "# load data from the separate csv files - for stack- and blender training\n",
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "print(f\"train_df.shape : {train_df.shape}\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "print(f\"test_df.shape : {test_df.shape}\")\n",
    "\n",
    "# PREPARE DATA:\n",
    "train_df = scale_dataframe(train_df, column_names_to_scale=None, exempt_last_column=True)\n",
    "test_df = scale_dataframe(test_df, column_names_to_scale=None, exempt_last_column=True)\n",
    "\n",
    "train_ds = WineDataSet(data_df=train_df)\n",
    "test_ds = WineDataSet(data_df=test_df)\n",
    "\n",
    "BATCH_SIZE=64\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fad2a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.683692</td>\n",
       "      <td>2.629722</td>\n",
       "      <td>-1.430366</td>\n",
       "      <td>-0.720680</td>\n",
       "      <td>-0.449850</td>\n",
       "      <td>-0.117450</td>\n",
       "      <td>-0.266898</td>\n",
       "      <td>-1.851571</td>\n",
       "      <td>0.102075</td>\n",
       "      <td>0.343974</td>\n",
       "      <td>2.145643</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339680</td>\n",
       "      <td>-0.244747</td>\n",
       "      <td>0.397739</td>\n",
       "      <td>-0.846029</td>\n",
       "      <td>-0.449850</td>\n",
       "      <td>-0.336727</td>\n",
       "      <td>-0.357460</td>\n",
       "      <td>-1.068214</td>\n",
       "      <td>0.620864</td>\n",
       "      <td>-0.516181</td>\n",
       "      <td>1.340366</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.577724</td>\n",
       "      <td>0.063232</td>\n",
       "      <td>0.079808</td>\n",
       "      <td>-0.950486</td>\n",
       "      <td>0.366131</td>\n",
       "      <td>-0.281908</td>\n",
       "      <td>0.185910</td>\n",
       "      <td>-0.725495</td>\n",
       "      <td>-0.027622</td>\n",
       "      <td>-0.172119</td>\n",
       "      <td>0.132450</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.374451</td>\n",
       "      <td>0.473870</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>-0.093937</td>\n",
       "      <td>-0.087192</td>\n",
       "      <td>-0.501185</td>\n",
       "      <td>-1.104593</td>\n",
       "      <td>-0.704513</td>\n",
       "      <td>0.620864</td>\n",
       "      <td>0.946083</td>\n",
       "      <td>1.179311</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.612495</td>\n",
       "      <td>0.268551</td>\n",
       "      <td>4.530844</td>\n",
       "      <td>0.428349</td>\n",
       "      <td>-0.540515</td>\n",
       "      <td>0.759658</td>\n",
       "      <td>1.340571</td>\n",
       "      <td>0.029885</td>\n",
       "      <td>1.334198</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.937727</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.683692  2.629722 -1.430366 -0.720680 -0.449850 -0.117450 -0.266898   \n",
       "1  0.339680 -0.244747  0.397739 -0.846029 -0.449850 -0.336727 -0.357460   \n",
       "2  0.577724  0.063232  0.079808 -0.950486  0.366131 -0.281908  0.185910   \n",
       "3 -0.374451  0.473870  0.000325 -0.093937 -0.087192 -0.501185 -1.104593   \n",
       "4 -0.612495  0.268551  4.530844  0.428349 -0.540515  0.759658  1.340571   \n",
       "\n",
       "         7         8         9         10   11  \n",
       "0 -1.851571  0.102075  0.343974  2.145643  8.0  \n",
       "1 -1.068214  0.620864 -0.516181  1.340366  8.0  \n",
       "2 -0.725495 -0.027622 -0.172119  0.132450  5.0  \n",
       "3 -0.704513  0.620864  0.946083  1.179311  7.0  \n",
       "4  0.029885  1.334198 -0.000088  0.937727  6.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check after scaling:\n",
    "\n",
    "#train_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "516df386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Epoch: 50 -----\n",
      "Epoch loss: 0.018122082163291517\n",
      "Epoch accuracy: 0.5587334014300307\n",
      "\n",
      "----- Epoch: 100 -----\n",
      "Epoch loss: 0.01689246232955278\n",
      "Epoch accuracy: 0.5903983656792645\n",
      "\n",
      "----- Epoch: 150 -----\n",
      "Epoch loss: 0.016465491610479305\n",
      "Epoch accuracy: 0.6108273748723186\n",
      "\n",
      "----- Epoch: 200 -----\n",
      "Epoch loss: 0.01655414222575062\n",
      "Epoch accuracy: 0.6404494382022472\n",
      "\n",
      "----- Epoch: 250 -----\n",
      "Epoch loss: 0.016574289995998113\n",
      "Epoch accuracy: 0.6435137895812053\n",
      "\n",
      "----- Epoch: 300 -----\n",
      "Epoch loss: 0.01676062507454051\n",
      "Epoch accuracy: 0.6618998978549541\n",
      "\n",
      "----- Epoch: 350 -----\n",
      "Epoch loss: 0.01747330283485467\n",
      "Epoch accuracy: 0.6292134831460674\n",
      "\n",
      "----- Epoch: 400 -----\n",
      "Epoch loss: 0.017354104199862455\n",
      "Epoch accuracy: 0.6414708886618999\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer for tensorboard:\n",
    "writer = SummaryWriter(\"./tensorbd_logs\")\n",
    "\n",
    "# create new model instance:\n",
    "#net_model = WineNetwork().to(device) \n",
    "net_model = WineNetwork()\n",
    "\n",
    "# loss function:\n",
    "# cross-entropy:\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer:\n",
    "# adam:\n",
    "#OPTIMIZER_NAME = \"ADAM\"\n",
    "#LEARNING_RATE = 1e-3\n",
    "#OPTIMIZER = torch.optim.Adam(net_model.parameters(), lr=LEARNING_RATE)\n",
    "# sgd:\n",
    "OPTIMIZER_NAME = \"SGD\"\n",
    "LEARNING_RATE = 1e-3\n",
    "OPTIMIZER = torch.optim.SGD(net_model.parameters(), lr= LEARNING_RATE, momentum=0.9)\n",
    "\n",
    "# training parameters:\n",
    "EPOCHS = 400\n",
    "WRITE_LOG_AFTER_EPOCHS = 50\n",
    "\n",
    "best_model_name = \"\"\n",
    "max_correct = float(\"-inf\")\n",
    "\n",
    "for ep in range(1, EPOCHS+1):        \n",
    "       \n",
    "        # put model in train mode:\n",
    "        net_model.train()\n",
    "        (train_loss, train_no_correct) = train_loop(train_dl, net_model, loss_fn, OPTIMIZER)\n",
    "              \n",
    "        # switch model to to evaluation mode:\n",
    "        net_model.eval()\n",
    "        (test_loss, test_no_correct) = test_loop(test_dl, net_model, loss_fn)\n",
    "\n",
    "        if(test_no_correct > max_correct):\n",
    "            max_correct = test_no_correct\n",
    "            if(best_model_name):\n",
    "                os.remove(best_model_name)\n",
    "            best_model_name = \"./net_model_\" + str(test_no_correct) + \"_\" + str(LEARNING_RATE) + \"_\" + str(ep) + \"_\" + str(BATCH_SIZE) + \"_\" + OPTIMIZER_NAME + \".pt\"\n",
    "            torch.save(model.state_dict(), best_model_name)\n",
    "\n",
    "        writer.add_scalar(\"Loss/test\", test_loss/ len(test_ds), ep)\n",
    "        writer.add_scalar(\"Accuracy/test\", test_no_correct/ len(test_ds), ep)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss/ len(train_ds), global_step=ep)\n",
    "        writer.add_scalar(\"Accuracy/train\", train_no_correct/ len(train_ds), global_step=ep)\n",
    "       \n",
    "        if ep % WRITE_LOG_AFTER_EPOCHS == 0:\n",
    "            print(f\"\\n----- Epoch: {ep} -----\")\n",
    "            print(f\"Epoch loss: {test_loss/ len(test_ds)}\")\n",
    "            print(f\"Epoch accuracy: {test_no_correct/ len(test_ds)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d543ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"inf\") > 44"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b56c7f",
   "metadata": {},
   "source": [
    "### Try and Improve - best Model ###\n",
    "\n",
    "model: model_640_0.001_369_64_SGD.pt <br>\n",
    "<br>\n",
    "Training parameters:  <br>\n",
    "optimizer_name = \"SGD\" <br>\n",
    "learning_rate = 1e-3 <br>\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9) <br>\n",
    "epochs = 400 <br>\n",
    "test_size=0.2 <br>\n",
    "batch_size=64 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45abc9",
   "metadata": {},
   "source": [
    "net_model_660_0.001_299_64_SGD.pt <br>\n",
    "\n",
    "OPTIMIZER_NAME = \"SGD\" <br>\n",
    "LEARNING_RATE = 1e-3 <br>\n",
    "OPTIMIZER = torch.optim.SGD(net_model.parameters(), lr= LEARNING_RATE, momentum=0.9) <br>\n",
    "\n",
    "training parameters: <br>\n",
    "EPOCHS = 400 <br>\n",
    "BATCH_SIZE=64 <br>\n",
    "test_size=0.2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2da2a01206928b59d169f1baf1b7bbbb4ecd1378e37d125bf69781943a3c02b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
